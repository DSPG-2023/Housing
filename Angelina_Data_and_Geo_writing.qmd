---
title: "Data Collection Section"
---

## Data Collection

We first gathered house images manually from Kaggle, amassing a total of approximately 35,000 images. Kaggle is a website for hosting and sharing datasets. This website has many useful datasets for building AI models, which is why we decided to use images from Kaggle to aid in the initial AI model building process.

Since we needed more relevant images specific to Iowa, we decided to web scrape from other sources. Through this technique, we automated the process of acquiring images. Despite this improvement, we still had to manually sift through the gathered images, distinguishing those of high quality and suitable features for training our model from those of poorer quality.

WinVest was another DSPG project that involved the communities of Grundy Center, New Hampton and Independence. We chose to web scrape housing data from these three communities for our project, and were able to use images from WinVest.

### What is Web Scraping?

Web scraping is like a digital tool that automatically collects information from websites, allowing us to gather data quickly without manual searching.

Before starting any web scraping, our team had a plan to scrape the following websites for image, address, and attribute data:

-   [**Zillow**](https://www.zillow.com/?utm_medium=cpc&utm_source=google&utm_content=1471764169%7C65545421228%7Caud-352785741564:kwd-570802407%7C603457706088%7C&semQue=null&gclid=EAIaIQobChMI-Nv7oPL3_wIVWSazAB0eyA9CEAAYASAAEgKaafD_BwE){target="_blank"}, [**Trulia**](https://www.trulia.com/){target="_blank"}, and [**Realtor.com**](https://www.realtor.com/)

-   **County Assessor Websites**

    These are online portals provided by local government entities that offer property-related information, including property records, tax assessments, and maps. Users can access details about property ownership and tax information.

-   [**Vanguard Appraisals, Inc**](https://www.iowaassessors.com/){target="_blank"}

    Vanguard Appraisals, Inc is a company that specializes in providing property appraisal services and software solutions for assessment in cities, counties and township Assessment Offices.-

-   [**Beacon**](https://beacon.schneidercorp.com/){target="_blank"} **by Schneider Geospatial**

    This is a software platform used for property assessment and tax administration. It helps government agencies manage property data, valuation processes, and tax assessments by offering geospatial mapping, data analytics, and reporting capabilities.

-   **Google Street View**

    To scrape images from Google Street View using the Google API, you can utilize the Google Street View Image API. You would need desired coordinates or addresses to retrieve the Street View images, and then save the images obtained from the API response to your local storage or database for further use.

Upon further reflection, we realized that Zillow owns Trulia. The major difference in the two sites is the Zestimate provided on Zillow. Because we were interested in the housing value, we chose to scrape Zillow out of the two.

We collected data from the following sites:

-   Zillow
-   Polk County Assessor Website
-   Vanguard
-   Beacon
-   Google Street View

### Address Collection

Lists of addresses and other information for Iowa cities are very hard to come by. It is not likely that such lists exists for cities. This is why we planned to scrape data.

Vanguard and Beacon are companies used by most cities in Iowa. They hold much of the state's housing data. This is why the data collection from these websites were of importance.

Vanguard has a GIS tool available that allowed us to select portions of cities and download addresses and parcel numbers. Only data for Independence was available through Vanguard. Vanguard limits the number of parcels we can select at a time for download.

Beacon has more protection against web scraping than Vanguard. Also, the GIS tool was not available for Beacon data. The process of downloading data one house at a time would be extremely time consuming. For example, Grundy Center, a city of around 2,000 people, has approximately 1,200 addresses. Collecting data for 1,200 addresses without automation would take a very long time.

To scrape addresses and parcel numbers, we used the [Instant Data Scraper Tool](https://chrome.google.com/webstore/detail/instant-data-scraper/ofaokhiedipichpaobibbnahnkdoiiah). This scraper provided us with CSV files of house data.

Once the data had been scraped, we found that the CSV files provided us with a format that was not ideal.

Examples of issues we encountered with the CSV files:

-   Many of the cells contained hidden characters.

-   New lines within the cells.

To fix this file format, we used Excel's Text-to-Columns tool to organize text, and Excel functions to separate and combine sections, and the Excel Find and Replace tool to remove unwanted characters.

In addition to re-formatting data, it was also necessary to create links for the Google Street View image collection process. Below is an example of a link to a Google Street View Image.

**https://maps.googleapis.com/maps/api/streetview?size=800x800&location=303+I+AVE,+GRUNDY+CENTER+IOWA**

More information [here](https://gavinfishy.github.io/Gavin_DSPG_Blog/posts/Gavin-Fisher_guide_w7/full_guide.html#address-collection-and-cleaning){target="_blank"}.

## Geographic Visualization

#### What is GIS and how is it used in this project?

A Geographic Information System (GIS) is a spatial system that is used to analyze, display and store geographically referenced information. GIS uses data that is attached to a unique location and can be useful for identifying problems and trends.

More information [here](https://www.esri.com/en-us/what-is-gis/overview).

Mapping our house quality output using GIS enables us to visualize the AI-model output for vegetation, siding, gutters, and roof characteristics. This will allow us to visualize locations of houses in good conditions versus poor condition.

In the future, it could be beneficial to utilize statistical analysis techniques to understand the spatial relationship between data and visualize clusters.

#### Geocoding Addresses

To visualize addresses for the communities, first we needed to geocode each address. Because GIS does not always know the exact location of an address, the latitude and longitude of addresses are needed. There are many types of software that can be used to geocode addresses.

QGIS is an open-source GIS software. We first geocoded addresses by using the QGIS Plugin called MMQGIS. When using this method, the plugin would crash and fail to geocode all the addresses. Because of this, we geocoded addresses using R instead. Base code was from [storybench](https://www.storybench.org/geocode-csv-addresses-r/){target="_blank"}.

Below is an image of a CSV file with addresses latitude and longitude.

![](ogden_geocoded_addresses.png){fig-align="center" width="459"}

More information [here](https://1angelinaevans.github.io/AngelinaEvansBlog/posts/Week6TeamBlog/Week6TeamBlog.html#mapping){target="_blank"}.

#### Mapping the Data

We first created maps in QGIS.

![](/images/siding_slater.png)

We later realized we can use Tableau for better data connections and visualizations. Tableau is a software used for data visualization. Tableau was more appealing because of its ability to create maps and compare data between cities using the same software. ArcGIS is another viable option for mapping, but it requires a licence and for the reasons above, we chose to use Tableau.

We created a step by step process for creating a tableau dashboard showing the output from the AI Models and mapping it to the already geocoded addresses.

Click [here](https://1angelinaevans.github.io/AngelinaEvansBlog/posts/MappingHouseData/MappingHouseQuality.html){target="_blank"} for more information.

### Tableau Dashboard

![](/images/screenshot_dashboardnew.png){width="619"}

#### [Tableau Dashboard](https://1angelinaevans.github.io/AngelinaEvansBlog/posts/House%20Quality%20Dashboards/HouseQualityDashboard.html){target="_blank"}
